<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Titan de Tian</title>
    <link>https://ThisIsTian.github.io/</link>
    <description>Recent content on Titan de Tian</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>xtiant1@gmail.com (Tiantian Xie)</managingEditor>
    <webMaster>xtiant1@gmail.com (Tiantian Xie)</webMaster>
    <lastBuildDate>Tue, 07 Sep 2021 00:13:07 -0400</lastBuildDate>
    
	<atom:link href="https://ThisIsTian.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Cache and Bandwidth Aware Real-time Subsurface Scattering</title>
      <link>https://ThisIsTian.github.io/publication/cache-and-bandwidth-aware-real-time-subsurface-scattering/</link>
      <pubDate>Tue, 07 Sep 2021 00:13:07 -0400</pubDate>
      <author>xtiant1@gmail.com (Tiantian Xie)</author>
      <guid>https://ThisIsTian.github.io/publication/cache-and-bandwidth-aware-real-time-subsurface-scattering/</guid>
      <description>&lt;div class=&#34;publication-preview-teaser&#34;&gt;

&lt;div class=&#34;publication-page&#34;&gt;
&lt;image src=&#34;../../Image/publication/dissertation/MetaHuman.png&#34;&gt;&lt;/image&gt;
&lt;/div&gt;

&lt;div class=&#34;project-page&#34;&gt;
&lt;image src=&#34;../../Image/publication/dissertation/MetaHuman.png&#34;&gt;&lt;/image&gt;
&lt;/div&gt;

&lt;div class=&#34;teaser-caption&#34;&gt;
Figure 1: MetaHuman rendered with our proposed subsurface scattering algorithm
          in Unreal Engine in real time.
&lt;/div&gt;
&lt;/div&gt;

&lt;p style=&#34;text-align: justify; word-wrap: break-word; font-size:14px&#34;&gt;
&lt;em&gt;Abstract&lt;/em&gt;: Photo-realistic subsurface scattering is a demanding feature in many real-time
                   applications, especially in next-generation games and virtual productions where the
                   uncanny valley needs to be addressed for real-time human skin rendering. Most
                   importantly, it must be addressed in milliseconds or less without visible quality
                   compromise. These quality and performance demands are prohibitively expensive
                   when using Monte Carlo sampling for subsurface scattering. Moreover, real-time
                   rendering is limited by hardware capability and GPU cache architectures. This
                   dissertation explores novel algorithms for high-quality photo-realistic real-time subsurface
                   scattering with cache incoherence and limited bandwidth.&lt;br&gt;

                   &amp;nbsp;&amp;nbsp;To achieve this, a new generic taxonomy is proposed for heterogeneous realtime
                   rendering to identify techniques that can improve bandwidth and cache utilization.
                   A single pass, variance guided, and generic O(1) real-time adaptive sampling
                   technique is proposed to minimize bandwidth demands and improve cache utilization.
                   This adaptive sampling pass works with different global temporal accumulation
                   techniques (e.g., Temporal Anti-Aliasing and Deep Learning Super Sampling) to further improve quality. We propose a new technique, adaptive filtered importance
                   sampling (AFIS), based on our single pass adaptive sampling technique and
                   filtered importance sampling. A hybrid AFIS and the separable approximation technique
                   allows the user to balance quality and performance. To deal with instability
                   during dynamic lighting, a novel use of Control Variates (CV) in the sample domain
                   instead of shading domain is proposed.&lt;br&gt;
                   &amp;nbsp;&amp;nbsp;Our algorithm induces as little as one texture overhead to a real-time rendering
                   engine, and has been battle tested in the Unreal Engine, a commercial game engine.&lt;/p&gt;

&lt;!--- #### Download #### ---&gt;

&lt;p&gt;&lt;font size = &#34;2&#34;&gt;&lt;/p&gt;

&lt;div class=&#34;downloadable&#34;&gt;
&lt;a href=&#34;../../publication/SSS_2021_tiantian_dissertation.pdf&#34;&gt;
    &lt;div&gt;
    &lt;image style=&#34;float: left; width: 12pt; vertical-align:middle&#34; src=&#34;../../icons8-pdf-40.png&#34;/&gt;
    &lt;span&gt;Dissertation (23.2 MB PDF)&lt;/span&gt;
    &lt;/div&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;div class=&#34;downloadable&#34;&gt;
&lt;a href=&#34;../../publication/Defense_Slides.pdf&#34;&gt;
    &lt;div&gt;
    &lt;image style=&#34;float: left; width: 12pt; vertical-align:middle&#34; src=&#34;../../icons8-pdf-40.png&#34;/&gt;
    &lt;span&gt;Defense Slides (89.1 MB PDF)&lt;/span&gt;
    &lt;/div&gt;
&lt;/a&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Real-time Subsurface Control Variates: Temporally Stable Adaptive Sampling</title>
      <link>https://ThisIsTian.github.io/publication/real-time-subsurface-control-variates/</link>
      <pubDate>Wed, 10 Mar 2021 22:14:44 -0500</pubDate>
      <author>xtiant1@gmail.com (Tiantian Xie)</author>
      <guid>https://ThisIsTian.github.io/publication/real-time-subsurface-control-variates/</guid>
      <description>&lt;div class=&#34;publication-preview-teaser&#34;&gt;

&lt;div class=&#34;publication-page&#34;&gt;
&lt;image src=&#34;../../Image/publication/i3d2021/RegularLighting_Scene_171.png&#34;&gt;&lt;/image&gt;
&lt;/div&gt;

&lt;div class=&#34;project-page&#34;&gt;
&lt;image src=&#34;../../Image/publication/i3d2021/Teaser.png&#34;&gt;&lt;/image&gt;
&lt;/div&gt;

&lt;div class=&#34;teaser-caption&#34;&gt;
Figure 1: Dynamic subsurface scene just after light has been turned off. Our method has consistently lower
          sample count (d) than SPVG [Xie et al. 2020] (c) at this frame. It leads to lower sampling pass time in dynamic
          lighting from 12.9 ms to 5.2 ms at 3360 × 1440 (×2.5), while maintaining good quality (47.5 dB) vs SPVG (48.6
          dB). Separable (b) runs fastest for the whole subsurface pass at 4.0 ms, however, with visible banding artifacts.
&lt;/div&gt;
&lt;/div&gt;

&lt;p style=&#34;text-align: justify; word-wrap: break-word; font-size:14px&#34;&gt;
&lt;em&gt;Abstract&lt;/em&gt;: Real-time adaptive sampling is a new technique recently proposed for efficient importance sampling in real-time
            Monte Carlo sampling in subsurface scattering. It adaptively places samples based on variance tracking
            to help escape the uncanny valley of subsurface rendering. However, the occasional performance drop due to
            temporal lighting dynamics (e.g., guns or lights turning on and off) could hinder adoption in games or other
            applications where smooth high frame rate is preferred. In this paper we propose a novel usage of Control
            Variates (CV) in the sample domain instead of shading domain to maintain a consistent low pass time. Our
            algorithm seamlessly reduces to diffuse with zero scattering samples for sub-pixel scattering. We propose a
            novel joint-optimization algorithm for sample count and CV coefficient estimation. The main enabler is our
            novel time-variant covariance updating method that helps remove the effect of recent temporal dynamics
            from variance tracking. Since bandwidth is critical in real-time rendering, a solution without adding any extra
            textures is also provided.&lt;/p&gt;

&lt;!--- #### Download #### ---&gt;

&lt;p&gt;&lt;font size = &#34;2&#34;&gt;&lt;/p&gt;

&lt;div class=&#34;downloadable&#34;&gt;
&lt;a href=&#34;../../publication/I3D_2021_preprint.pdf&#34;&gt;
    &lt;div&gt;
    &lt;image style=&#34;float: left; width: 12pt; vertical-align:middle&#34; src=&#34;../../icons8-pdf-40.png&#34;/&gt;
    &lt;span&gt;Preprint (51.3 MB PDF)&lt;/span&gt;
    &lt;/div&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div class=&#34;downloadable&#34;&gt;
&lt;a href=&#34;../../publication/I3D_2021_preprint_low_res.pdf&#34;&gt;
    &lt;div&gt;
    &lt;image style=&#34;float: left; width: 12pt; vertical-align:middle&#34; src=&#34;../../icons8-pdf-40.png&#34;/&gt;
    &lt;span&gt;Preprint-small (7.1 MB PDF)&lt;/span&gt;
    &lt;/div&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div class = &#34;downloadable&#34;&gt;
&lt;a href=&#34;../../publication/I3D_2021_supplementary_low_res.pdf&#34;&gt;
    &lt;div&gt;
    &lt;image style=&#34;float: left; width: 12pt; vertical-align:middle&#34; src=&#34;../../icons8-pdf-40.png&#34;/&gt;
    &lt;span&gt;Supplementary (642 KB PDF)&lt;/span&gt;
    &lt;/div&gt;
&lt;/a&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Real-time subsurface scattering with single pass variance-guided adaptive importance sampling</title>
      <link>https://ThisIsTian.github.io/publication/real-time-subsurface-with-adaptive-sampling/</link>
      <pubDate>Wed, 06 May 2020 08:45:22 -0800</pubDate>
      <author>xtiant1@gmail.com (Tiantian Xie)</author>
      <guid>https://ThisIsTian.github.io/publication/real-time-subsurface-with-adaptive-sampling/</guid>
      <description>&lt;div class=&#34;publication-preview-teaser&#34;&gt;
&lt;image src=&#34;../../Image/publication/i3d2020/subsurfaceteaser.png&#34;&gt;&lt;/image&gt;
&lt;div class=&#34;teaser-caption&#34;&gt;
Figure 1: Subsurface rendering comparison from close to far at 1920x1080 on NVIDIA Quadro P4000 (implemented in UE4). (a) our adaptive sampling algorithm ($σ\\_0^2$ = 0.001, κ = 0.2, $b\\_{min}$ = 8 spp, $b\\_{max}$ = 64 spp), (b) Golubev [2018]’s sampling model in our framework with 64spp, (c) a Baseline fixed 64-sample implementation without our proposed acceleration techniques, (d) Separable screen-space diffusion. (e) Visualization of our adaptive sample count for each view. Our quality is higher than Baseline in all three scenarios (close skin patch, ear, and front). Moreover, our algorithm runs faster on the close skin patch with an acceleration of up to 91.07× (2.78 ms vs 253.18 ms). In addition, our algorithm enables better quality with run time comparable or even better than Separable. Error measurements are PSNR for the subsurface, as compared to a reference image at 2k samples per pixel. Digital Mike ©Epic Games, Inc.
&lt;/div&gt;
&lt;/div&gt;

&lt;p style=&#34;text-align: justify; word-wrap: break-word; font-size:14px&#34;&gt;
&lt;em&gt;Abstract&lt;/em&gt;: In real-time applications, it is difficult to simulate realistic subsurface scattering with differing degrees
translucency. Burley’s reflectance approximation by empirically fitting the diffusion profile as a whole makes
it possible to achieve realistic looking subsurface scattering for different translucent materials in screen
space. However, achieving a physically correct result requires real-time Monte Carlo sampling of the analytic
importance function per pixel per frame, which seems prohibitive to achieve. In this paper, we propose an
approximation of the importance function that can be evaluated in real-time. Since subsurface scattering
is more pronounced in certain regions (e.g., with light gradient change), we propose an adaptive sampling
method based on temporal variance to lower the required number of samples. We propose a one phase
adaptive sampling pass that is unbiased, and able to adapt to scene changes due to motion and lighting.
To further improve the quality, we explore temporal reuse with a guiding pass prior to the final temporal
anti-aliasing (TAA) phase that further improves the quality. Our local guiding pass does not constrain the
TAA implementation, and only requires one additional texture to be passed between frames. Our proposed
variance-guided algorithm has the potential to make stochastic sampling algorithm effective for real-time
rendering.&lt;/p&gt;

&lt;!--- #### Download #### ---&gt;

&lt;p&gt;&lt;font size = &#34;2&#34;&gt;&lt;/p&gt;

&lt;div class = &#34;downloadable&#34;&gt;
&lt;a href=&#34;../../publication/spvg_xie_2020_I3D.pdf&#34;&gt;
    &lt;div&gt;
    &lt;image style=&#34;float: left; width: 12pt; vertical-align:middle&#34; src=&#34;../../icons8-pdf-40.png&#34;/&gt;
    &lt;span&gt;Preprint (75 MB PDF)&lt;/span&gt;
    &lt;/div&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div class = &#34;downloadable&#34;&gt;
&lt;a href=&#34;../../publication/spvg_xie_2020_I3D_small.pdf&#34;&gt;
    &lt;div&gt;
    &lt;image style=&#34;float: left; width: 12pt; vertical-align:middle&#34; src=&#34;../../icons8-pdf-40.png&#34;/&gt;
    &lt;span&gt;Preprint-small (7.3 MB PDF)&lt;/span&gt;
    &lt;/div&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div class = &#34;downloadable&#34;&gt;
&lt;a href=&#34;https://dl.acm.org/doi/10.1145/3384536&#34;&gt;
    &lt;div&gt;
    &lt;image style=&#34;float: left; width: 12pt;vertical-align:middle&#34; src=&#34;../../icons8-home-40.png&#34;/&gt;
    &lt;span&gt;Publisher&#39;s homepage&lt;/span&gt;
    &lt;/div&gt;
&lt;/a&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Post 2: Add Volumetric Material Support</title>
      <link>https://ThisIsTian.github.io/post/add-volumetric-material-support/</link>
      <pubDate>Sun, 06 Jan 2019 08:48:15 -0800</pubDate>
      <author>xtiant1@gmail.com (Tiantian Xie)</author>
      <guid>https://ThisIsTian.github.io/post/add-volumetric-material-support/</guid>
      <description>Introduction Volume objects are a good fit for ATAA, because high luminance variance can be introduced by 1) randomization of ray marching start position to mitigate slicing effect, and 2) object motions that create blurry and ghosting effects within the volume object. If we replace those high variance pixels with correct tracing pixels, volume objects can be perfect rendered without any artifacts. The big picture above illustrates this point. In this post, I will show how I added correct ATAA support to custom volumetric material within the path tracer created in the last post.</description>
    </item>
    
    <item>
      <title>Post 1: Add ATAA Into UE4</title>
      <link>https://ThisIsTian.github.io/post/add-ataa-into-ue4/</link>
      <pubDate>Sun, 06 Jan 2019 08:45:22 -0800</pubDate>
      <author>xtiant1@gmail.com (Tiantian Xie)</author>
      <guid>https://ThisIsTian.github.io/post/add-ataa-into-ue4/</guid>
      <description>The original paper adaptive temporal antialiasing by Adam Marrs et al. introduced how ATAA can be implemented with RTX in a summary. In this post, the focus is on the technique and problems I came across when adding ATAA to UE4 in a course project without RTX.
Segmentation The first step to implement ATAA is to classify pixel types and record history information. In the paper, the pixel types include: FXAA, TAA, ATAA.</description>
    </item>
    
    <item>
      <title>Adaptive Temporal Antialiasing Without RTX</title>
      <link>https://ThisIsTian.github.io/post/adaptive-temporal-antialiasing-without-rtx/</link>
      <pubDate>Sun, 06 Jan 2019 00:05:14 -0800</pubDate>
      <author>xtiant1@gmail.com (Tiantian Xie)</author>
      <guid>https://ThisIsTian.github.io/post/adaptive-temporal-antialiasing-without-rtx/</guid>
      <description>Introduction TL;DR - I was working on volumetric data in UE4 before starting this project. The rendering was a little burry when the camera moved. However, it was fine at that time because only static screenshots were needed. Anyhow, it got my attention. So, for the course project for the graphics for games class instructed by Dr. Marc Olano, I tried to implement adaptive temporal antialiasing (ATAA) in UE4 4.</description>
    </item>
    
    <item>
      <title>About me</title>
      <link>https://ThisIsTian.github.io/page/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>xtiant1@gmail.com (Tiantian Xie)</author>
      <guid>https://ThisIsTian.github.io/page/about/</guid>
      <description>Hi, my name is Tiantian Xie (Tientien Hsieh), who is interested in Real-time rendering, Game and Machine/Deep Learning. I was advised by Dr. Marc Olano and received my PhD degree in Computer Science from UMBC in 2021. I currently work at Epic Games as Rendering Programmer.
My recent work is focused on adaptive sampling techniques for real-time rendering that can be directly adapted into game engines with low computing and bandwidth overhead.</description>
    </item>
    
  </channel>
</rss>