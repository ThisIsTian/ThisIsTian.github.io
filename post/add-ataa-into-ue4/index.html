<!DOCTYPE html>
<html lang="en">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Post 1: Add ATAA Into UE4 - Titan de Tian</title>
  <meta property="og:title" content="Post 1: Add ATAA Into UE4" />
  <meta name="twitter:title" content="Post 1: Add ATAA Into UE4" />
  <meta name="description" content="The original paper adaptive temporal antialiasing by Adam Marrs described how ATAA can be implemented in a summary. Yet it did not reveal too much technique details for each step in UE4. In this post, I focus on the technique and problem I came across when adding ATAA to UE4 in my course project without RTX.
Segmentation The first step to implement ATAA is to classify pixel types and record history information.">
  <meta property="og:description" content="The original paper adaptive temporal antialiasing by Adam Marrs described how ATAA can be implemented in a summary. Yet it did not reveal too much technique details for each step in UE4. In this post, I focus on the technique and problem I came across when adding ATAA to UE4 in my course project without RTX.
Segmentation The first step to implement ATAA is to classify pixel types and record history information.">
  <meta name="twitter:description" content="The original paper adaptive temporal antialiasing by Adam Marrs described how ATAA can be implemented in a summary. Yet it did not reveal too much technique details for each step in UE4. In this post, …">
  <meta name="author" content="Tiantian Xie"/><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "Titan de Tian",
    
    "url": "https://ThisIsTian.github.io"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https://ThisIsTian.github.io"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "https://ThisIsTian.github.io",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "https://ThisIsTian.github.io/post/add-ataa-into-ue4/",
          "name": "Post 1 add a t a a into u e4"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : "Tiantian Xie"
  },
  "headline": "Post 1: Add ATAA Into UE4",
  "description" : "The original paper adaptive temporal antialiasing by Adam Marrs described how ATAA can be implemented in a summary. Yet it did not reveal too much technique details for each step in UE4. In this post, I focus on the technique and problem I came across when adding ATAA to UE4 in my course project without RTX.
Segmentation The first step to implement ATAA is to classify pixel types and record history information.",
  "inLanguage" : "en",
  "wordCount": 3652,
  "datePublished" : "2019-01-06T08:45:22",
  "dateModified" : "2019-01-06T08:45:22",
  "image" : "https://ThisIsTian.github.io/favicon.ico",
  "keywords" : [ "" ],
  "mainEntityOfPage" : "https://ThisIsTian.github.io/post/add-ataa-into-ue4/",
  "publisher" : {
    "@type": "Organization",
    "name" : "https://ThisIsTian.github.io",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "https://ThisIsTian.github.io/favicon.ico",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>

<meta property="og:title" content="Post 1: Add ATAA Into UE4" />
<meta property="og:description" content="The original paper adaptive temporal antialiasing by Adam Marrs described how ATAA can be implemented in a summary. Yet it did not reveal too much technique details for each step in UE4. In this post, I focus on the technique and problem I came across when adding ATAA to UE4 in my course project without RTX.
Segmentation The first step to implement ATAA is to classify pixel types and record history information.">
<meta property="og:image" content="https://ThisIsTian.github.io/favicon.ico" />
<meta property="og:url" content="https://ThisIsTian.github.io/post/add-ataa-into-ue4/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="Titan de Tian" />
  <meta name="twitter:title" content="Post 1: Add ATAA Into UE4" />
  <meta name="twitter:description" content="The original paper adaptive temporal antialiasing by Adam Marrs described how ATAA can be implemented in a summary. Yet it did not reveal too much technique details for each step in UE4. In this post, …">
  <meta name="twitter:image" content="https://ThisIsTian.github.io/favicon.ico" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@ThisIsTian" />
  <meta name="twitter:creator" content="@ThisIsTian" />
  <link href='https://ThisIsTian.github.io/favicon.ico' rel='icon' type='image/x-icon'/>q  1qqqqqqqqqqq3qq3aaw `<KL>/KL> <meta property="og:image" content="https://ThisIsTian.github.io/favicon.ico" />
  <meta name="twitter:image" content="https://ThisIsTian.github.io/favicon.ico" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@ThisIsTian" />
  <meta name="twitter:creator" content="@ThisIsTian" />
  <meta property="og:url" content="https://ThisIsTian.github.io/post/add-ataa-into-ue4/" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="Titan de Tian" />

  <meta name="generator" content="Hugo 0.36.1" />
  <link rel="alternate" href="https://ThisIsTian.github.io/index.xml" type="application/rss+xml" title="Titan de Tian">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
  <link rel="stylesheet" href="https://ThisIsTian.github.io/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="https://ThisIsTian.github.io/css/highlight.min.css" /><link rel="stylesheet" href="https://ThisIsTian.github.io/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">



  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://ThisIsTian.github.io">Titan de Tian</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="https://ThisIsTian.github.io/">Blog</a>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent">Projects</a>
              <div class="navlinks-children">
                
                  <a href="https://ThisIsTian.github.io/post/adaptive-temporal-antialiasing-with-rtx-off">ATAA</a>
                
              </div>
            </li>
          
        
          
            <li>
              <a title="About" href="https://ThisIsTian.github.io/page/about/">About</a>
            </li>
          
        

        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="Titan de Tian" href="https://ThisIsTian.github.io">
            <img class="avatar-img" src="https://ThisIsTian.github.io/favicon.ico" alt="Titan de Tian" />
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  
    <div id="header-big-imgs" data-num-img=1 
      
         
          data-img-src-1="/Image/PathTracingIt.png" 
         
         data-img-desc-1="Path tracing the same UE4 scene"
      ></div>
  

  <header class="header-section has-img">
    
      <div class="intro-header big-img">
        
        <div class="container">
          <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
              <div class="post-heading">
                <h1>Post 1: Add ATAA Into UE4</h1>
                  
                  
                    <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on January 6, 2019
  
  
  
  
    &nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Tiantian Xie
  
</span>


                  
              </div>
            </div>
          </div>
        </div>
        <span class="img-desc" style="display: inline;"></span>
      </div>
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>Post 1: Add ATAA Into UE4</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on January 6, 2019
  
  
  
  
    &nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Tiantian Xie
  
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        

<p>The original paper <em>adaptive temporal antialiasing</em> by Adam Marrs described how ATAA can be implemented in a summary. Yet it did not reveal too much technique details for each step in UE4. In this post, I focus on the technique and problem I came across when adding ATAA to UE4 in my course project without RTX.</p>

<h2 id="segmentation">Segmentation</h2>

<p>The first step to implement ATAA is to classify pixel types and record history information. In the paper, the pixel types include: FXAA, TAA, ATAA. The relevant information is a ray tracing counter to avoid jittering if a pixel switches between TAA and ATAA frequently. I used one render target to record them in R and G channels, respectively. Besides, I also recorded a TAA artifact level (TAL) in B channel, which is the sum of luminance variance and the gradient magnitude of $3 \times 3$ Solel filter of depth texture. The higher this value is, the more artifacts TAA might produce. I stored this value for debugging and TAL visualization.</p>

<p>There are two interesting problem I have encountered to generate the segmentation texture.</p>

<ul>
<li><strong>How to pass the segmentation texture between frames</strong>. We can add the render target into any place that survives between frames. But a clean code is preferred in a large code base like UE4. Since segmentation texture can be updated in <code>PostProcessTemporalAA</code>, we can make use of how UE4 passes TAA history between frames to achieve this. After exploring the code base, I found <code>TemporalAAHistory</code> could serve this purpose. The lifecycle is shown in image a) as below:</li>
</ul>

<table>
<thead>
<tr>
<th align="center"><img src="https://ThisIsTian.github.io/Image/TemporalAAHistory.png" height="150"  /></th>
<th align="center"><img src="https://ThisIsTian.github.io/Image/EMVComparedtoVar.png"  height="150"/></th>
</tr>
</thead>

<tbody>
<tr>
<td align="center">a) Lifecycle of <code>TemporalAAHistory</code>.</td>
<td align="center">b) Variance comparison (<a href="https://gist.github.com/windywell/f100674b1d4b50246e089cd55ae36074" target="_blank">gist</a>)</td>
</tr>
</tbody>
</table>

<p>This field is updated every frame from the <code>ScenePendingPrevFrameViewInfo</code> to <code>PrevFrameViewInfo</code> inside <code>PreVisibilityFrameSetup</code>.</p>

<ul>
<li><strong>Luminance variance</strong>. The naive solution is to record the luminance for N frames and apply the variance formula as
$$
V(X)=\frac{1}{N-1}\sum_{i=1}^N(x_i-\mu)^2
$$
However, this would require us to keep all $N$ render targets between frames, which is not economical. A better solution is one that we can update the variance online incrementally every frame. This is how TAA updates the pixel color of final rendering by applying exponential moving average. With the same idea, we can apply <a href="http://people.ds.cam.ac.uk/fanf2/hermes/doc/antiforgery/stats.pdf">exponential moving variance</a> (EMV) to achieve this as:
$$
\mu_n = \alpha \mu_{n-1} + (1-\alpha)x_n
$$
$$
\sigma^2_n=(1-\alpha)\sigma^2_{n-1}+\alpha(1-\alpha)(x_n-\mu_{n-1})^2
$$
where $\mu_n $ and $\sigma^2_n$ are the current exponential moving average and variance. $\alpha$ is the exponential weight. To illustrate whether EMV is suitable for this purpose, I applied both EMV and Variance to a 1D random signal, the result wqs shown in image b) above. It showed a high similarity between these two signals after <em>code start</em>.</li>
</ul>

<p>The image below shows a test scene and the corresponding segmentation texture. We can observe clear TAL as blue pixels especially for the volume object (You can open the image in a new window to see the detail).</p>

<table>
<thead>
<tr>
<th align="center"><img src="https://ThisIsTian.github.io/Image/SegmentScene.png"  /></th>
<th align="center"><img src="https://ThisIsTian.github.io/Image/SegmentSceneResult.png" /></th>
</tr>
</thead>

<tbody>
<tr>
<td align="center">Test Scene, a volume object above floor</td>
<td align="center">The segmentation render target</td>
</tr>
</tbody>
</table>

<p>The pseudo algorithm I used is as below:</p>

<pre><code class="language-C++">0     //Assume that P holds all the property of the current pixel.
1     if(PreviousOccluded(P.Position,P.Motion))
2     {
3         P.ClassificationHistory.Method = FXAA;
4         return;
5     }
6
7     //Reset classification method.
8     if(SignificatMotion(P.Motion))
9     {
10        P.ClassificationHistory.Method = FXAA;
11        P.Classificationhistory.RaytracingCount = 0;
12        return;
13    }
14
15    //Whether the curent pixel has recently been raytraced.
16    //It reduces flickering due to rapid shifts with motion.
17    if(P.ClassificationHistory.Method == ATAA &amp;&amp;
18        P.ClassificationHistory.RaytracingCount--&gt;0)
19    {
20        return;// because the method is ATAA
21    }
22
23    float TemporalLumiVar = GetTemporalLuminanceVariance();
24    float DepthMagnitude = Get3x3DepthMagnitudeWithSobel();
25
26    if(TemporalLumiVar+DepthMagnitude&gt;Threashold)
27    {
28        P.ClassificationHistory.Method = ATAA;
29        P.ClassificationHistory.RaytracingCount = ConstRaytracingCount;
30    }
31    else
32    {
33        P.ClassificationHistory.Method = TAA;
34    }
</code></pre>

<p>A special note is that if there is a significant motion for a certain pixel, we will need to reset the method. If there is a significant motion, I would assume that the quality of the pixel is not important. Therefore, an early termination is triggered at line 12 (If the quality of significant motion is also important, line 12 can be removed).</p>

<h2 id="sparse-path-tracing">Sparse Path Tracing</h2>

<p>Instead of ray tracing with RTX as described in the original paper, I created a path tracer with compute shader to replace samples with high TAL. Because path tracing would reveal more dynamic details. The main challenge here is to have the same rendering result for both rendering pipeline: path tracing and rasterization based shading in UE4. Otherwise, the ATAA step itself will bring mismatch artifacts as shown below.</p>

<table>
<thead>
<tr>
<th align="left"><img src="https://ThisIsTian.github.io/Image/ATAAMismatch Artifacts.png"/></th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">ATAA brings in mismatch artifacts if path tracing and the rasterization result does not match.</td>
</tr>
</tbody>
</table>

<p>Before solving this mismatch problem, let&rsquo;s first see how the mismatch happened.</p>

<h3 id="iterative-path-tracer">Iterative path tracer</h3>

<p><strong>Why an iterative path tracer</strong>: GPU is good at processing data in parallel in SIMD style by executing multiple threads at the same time (inside a warp on NVIDIA card). Yet it suffers from divergence problem caused by branches etc. Take branch as an example, if we have a path tracer executing recursively, it would create many different branching combination, yielding high divergence. If there is a ray that bounces 20 times while all others just once, all other threads need to wait for the single thread completion. After making it iterative, each pass will be independent. We can initialize 19 new rays to trace without the divergence brought in by recursive.</p>

<p>Another reason to choose an iterative path tracer for ATAA is to increase samples per pixel to reduce variance. Since samples to be traced are usually sparsely distributed. We need a way to only trace those pixels with high TAL. If it terminates early, we can sample the pixel again to reduce its variance.</p>

<p><strong>Implementation</strong>:  On each pixel that has high TAL value, a camera ray is initialized in the normalized device space (NDS) with a <em>sub-pixel sampling</em> pattern (i.e., Random, and Sobol) and then transformed into the world space. Starting from the first interaction with the scene object, it incrementally samples path vertex by multi-importance sampling (MIS) of light and the BRDF at the current vertex and tracing a new ray to the next vertex until max bounce or termination by Russian roulette. If any ray has early termination, it will immediately fire another camera ray. At last, the results are averaged for each pixel.</p>

<p>I did not go for more advanced path tracing method like Bidirectional or Photon mapping. If you are familiar with the basic techniques, just ignore the following sections and jump to <a href="#postprocess-modification">postprocess modification</a> where I show the modification to add ATAA to the post process in UE4.</p>

<h3 id="sub-pixel-sampling">Sub-pixel sampling</h3>

<p>The purpose for sub-pixel sampling in rendering is to reduce visual impact of aliasing artifacts. Aliasing artifacts are introduced when sampling frequency is lower than twice the max frequency present in the signal based on <a href="https://en.wikipedia.org/wiki/Nyquist–Shannon_sampling_theorem">Nyquist-Shannon sampling theorem</a>. Those artifacts are the low frequencies leaked by high frequency signals (Interestingly, if we have a well-tuned high frequency image, we can see a different image if we are filming it with a camera that has an imperfect low pass filter).</p>

<p>Sub-pixel sampling can change the sampling pattern from uniform to nonuniform. Nonuniform sampling turns artifact pattern into random noise, thus reduces the visual impacts to our eye. However, we only need one sample per pixel for final output. To achieve this, I filtered out the high frequency in the pixel region using Monte Carlo with a box filter kernel, which ends up as:
$$
f(x,y)_{filtered}=\frac{1}{N}\sum_{i=1}\frac{f(x_i,y_i)}{p(x_i,y_i)}
$$
where $f(x_i,y_i)$ is the sample result we get after path tracing at $(x_i,y_i)$. $p(x_i,y_i)$ is the probability density function
that this coordinate is sampled. If we further assume that the sampling is uniform, we have $p(x_i,y_i)=1$, which enables us to sample
the filtered pixel as a mean of all samples inside the pixel region.</p>

<p><strong>Result</strong>:
I tried two different sampling patterns with uniform distribution including: random and Sobol sequence to
generate 2D samples $(\varsigma_1, \varsigma_2) \in [0,1)^2$. The image below shows the comparison between a) random and c) Sobol sequence
with sky irradiance only. Image b) is generated with 512 bounces as the baseline. We can observe clear edges
with Sobol sequence as it will introduce known patterns. The edge is more smooth with random sampling.</p>

<table>
<thead>
<tr>
<th align="left"><img src="https://ThisIsTian.github.io/Image/Subpixel_Sampling.png" height="400"/></th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">Path tracing result with different sub-pixel sampling patterns. Early termination starts at the 4th bounce with Russian roulette. The sphere and box material was created with lambert BRDF. The only light in the scene is the sky irradiance which is represented as Order 3 Spherical harmonics.</td>
</tr>
</tbody>
</table>

<p>However, sampling is not an end story here. Since we have limited sampling budgets for each pixel in real-time rendering, blue noise is a better method according to the <a href="https://cs.dartmouth.edu/wjarosz/publications/subr16fourier.html">frequency analysis</a> course in SIGGRAPH Course 16&rsquo;. In short, a homogeneous sampling strategy which has less spectral energy concentration on low frequency introduces less error for real-time rendering where we do not have enough samples. Blue noise sampler meets this requirement. So, I chose it for BRDF sampling described in the next section.</p>

<h3 id="brdf-sampling-with-limited-budget">BRDF sampling with limited budget</h3>

<p>I only added Lambertian material at this moment to support ATAA (to identify the difference between path tracing and rasterization). Lambertian material has similar diffuse scattering radiance to all directions. In the incremental path tracing framework, Lambertian BRDF was used in the path throughput weight:</p>

<p>$$
\beta=\prod \frac{f(\omega_i,\omega_o)|n\cdot \omega_i|}{p(\omega_i,\omega_o)}
$$</p>

<p>where $f(\omega_i,\omega_o)$ is the phase function, which is equal to $\frac{1}{\pi}$ for Lambertian. $p(\omega_i,\omega_o)$ is the probability
distribution function. Since we have limited budget, cosine weighted sampling of BRDF is better than uniform, which makes
$p(\omega_i,\omega_o)=\frac{1}{\pi}$. To have cosine weighted hemisphere sampling, a simple method without coordinate space transform is to add the surface norm to a random uniform vector sampled on a unit sphere. Since we cannot afford too much rays for this sampling, I went for the method that has the best convergence rate when sample count is low, which lead me to <em>blue noise on unit sphere</em>.</p>

<p><strong>A little more about blue noise</strong>: There are several blogs about blue noise on 2D space. You can read more about it
from <a href="https://blog.demofox.org/2017/10/20/generating-blue-noise-sample-points-with-mitchells-best-candidate-algorithm/">demofox&rsquo;s blog about Mitchell’s Best Candidate Algorithm</a>
and <a href="http://momentsingraphics.de/?p=127">Christoph&rsquo;s free blue noise texture</a>. If you prefer generation speed,
Pixal&rsquo;s <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13472">EGSR 18&rsquo; Paper</a> is well worth reading.</p>

<p><strong>Blue noise on unit sphere</strong>: To generate sample points on unit sphere, I chose the algorithm to generate points with best blue noise
property offline and then upload an LUT to use in the shader. Mitchell&rsquo;s best candidate algorithm was selected because the closest neighbor
points have the largest distance based on Pixal&rsquo;s EGSR paper. Moreover, it was generated progressively, I can configure the number of sampling points to use in the shader with only one LUT. Although SIGGRAPH Course 2016 suggested CCVT (Capacity constrained Voronoi Tessellation) as it has the best convergence rate, I did not use it given the time limitation. The basic idea of Mitchell&rsquo;s best candidate algorithm is that at each iteration keep the random generated candidate that is furthest to the closest points already selected in previous iterations . A special note for using this algorithm on unit sphere, instead of using Euclidean distance, the <a href="https://en.wikipedia.org/wiki/Great-circle_distance">Great-circle distance</a> should be used to calculate the closest distance between two points on the sphere. The vector version which is handy is listed here:</p>

<p>$$
d=arctan(\frac{|\mathbf{p}_1 \times \mathbf{p}_2|}{\mathbf{p_1}\cdot\mathbf{p}_2})
$$</p>

<p>which is the arctan of the magnitude of the cross product of the two points $\mathbf{p_1}$ and $\mathbf{p_2}$ by their dot product.</p>

<p>The image below shows sample generations a) when the number of points is 2048 with blue noise on sphere (<a href="https://gist.github.com/windywell/99c72e0e993cb70cdd607a5516f99358">gist</a>), b) converted to cosine weighted sampling on hemisphere, c) looking down from Z Axis, and d) with random sampling and looking down from Z axis.</p>

<table>
<thead>
<tr>
<th align="center"><img src="https://ThisIsTian.github.io/Image/BlueNoise2048.png" height="300"/></th>
<th align="center"><img src="https://ThisIsTian.github.io/Image/BlueNoiseHemisphere.png" height="300"/></th>
</tr>
</thead>

<tbody>
<tr>
<td align="center">a) Blue noise sampling on unit sphere (N=2048)</td>
<td align="center">b) Converted to cosine weighted sampling on hemisphere</td>
</tr>

<tr>
<td align="center"><img src="https://ThisIsTian.github.io/Image/BlueNoiseDisc.png" height="300"/></td>
<td align="center"><img src="https://ThisIsTian.github.io/Image/RandomDisc.png" height="300"/></td>
</tr>

<tr>
<td align="center">c) Blue noise looking down from Z Axis</td>
<td align="center">d) Random sampling looking down from Z Axis</td>
</tr>
</tbody>
</table>

<p>It is clear that random sampling is clumpy. However, the blue noise can be better if we sample blue noise on a disk and then project it up onto a hemisphere. Nevertheless, I did not go this way. Because it requires an additional local coordinate construction and matrix multiplication at each interaction.</p>

<p><strong>Result</strong>: Below are two frames captured when two different BRDF sampling method is used while other paramters are fixed. If we use blue noise sampling, it has less clumpy sampling points over all. Therefore, in brighter region, it converges to bright faster, and in dark region it converges to dark faster. In order to see which one converges better, I set the max bounce per ray to 1, and fixed the sub-pixel sampling method to Sobol Sequence and the total bounce to 256.</p>

<table>
<thead>
<tr>
<th align="center"><img src="https://ThisIsTian.github.io/Image/BRDFRandom.png" alt="Random BRDF" /></th>
<th align="center"><img src="https://ThisIsTian.github.io/Image/BRDFBlueNoise.png" alt="BRDF sampled with Blue noise" /></th>
</tr>
</thead>

<tbody>
<tr>
<td align="center">Random Sampling</td>
<td align="center">Blue noise sampling</td>
</tr>
</tbody>
</table>

<p>The difference is minute. Yet if you observe it closely (open them in another tap), you will find the top right region of the box is brighter in blue noise sampling, and the ambient occlusion of the sphere is darker for blue noise.</p>

<h3 id="multiple-importance-sampling-of-light-and-brdf">Multiple importance sampling of light and brdf</h3>

<p>In the current implementation, I only added the sunlight in addition to the skylight. Because by default when you create an UE4 scene,
there are  sunlight and skylight in the scene.  However, if we only sample the BRDF of the material, we can hardly see them with
limited sample counts. To increase the efficiency of Monte Carlo integration, we can do multiple importance sampling that combines BRDF and light sampling.</p>

<p>To achieve this, we need to simplify the <a href="https://graphics.stanford.edu/courses/cs348b-03/papers/veach-chapter9.pdf">multi-sample estimator</a>:</p>

<p>$$
F=\sum_{i=1}^n\frac{1}{n_i}\sum_{j=1}^{n_i}w_i(X_{i,j}) \frac{f(X_{i,j})}{p_i(X_{i,j})}
$$</p>

<p>I have fixed the weighting function of both sampling strategy, and drawn one sample from each sampling technique, which simplified the importance sampling function as:</p>

<p>$$
F=w_1\frac{f(X_{1,1})}{p_1(X_{1,1})}+w_2\frac{f(X_{2,1})}{p_2(X_{2,1})}
$$</p>

<p>This combination will have high variance if the sunlight and BRDF sampling technique were bad. But I find it relatively good (I do not have too much experience about how good it can be with limited number of bounces). The image a) below shows the rendering result with random sub-pixel sampling and 64 bounce. Each ray can only bounce once, which is equal to 32 spp.</p>

<table>
<thead>
<tr>
<th align="center"><img src="https://ThisIsTian.github.io/Image/MISHardShadow.png" height="200"/></th>
<th align="center"><img src="https://ThisIsTian.github.io/Image/SceneExampleSS.png" height="200"/></th>
</tr>
</thead>

<tbody>
<tr>
<td align="center">a) Importance sampling of sunlight and skylight</td>
<td align="center">b) Default lighting in UE4</td>
</tr>

<tr>
<td align="center"><img src="https://ThisIsTian.github.io/Image/SoftShadow.png" height="200"/></td>
<td align="center"><img src="https://ThisIsTian.github.io/Image/MISSoftShadow.png" height="200"/></td>
</tr>

<tr>
<td align="center">c) Randomize light ray to create PCSS</td>
<td align="center">d) Soft shadow result for path tracing</td>
</tr>
</tbody>
</table>

<p>However, objects in UE4 cast soft shadows by default as shown in Image b) above.  A cascading shadow map is used to generate
softshadow. To add soft shadow in the path tracing framework, I randomized the light ray bouncing to the sun in the sun region
(shown in Image c)). Then, in the next iteration, it will bounce to an obstacle if it cannot hit the sun, or into the sun to
create lighting contribution. The final result is shown in image d). We can freely get percentage close soft shadow (PCSS). However, PCSS is costy in UE4.</p>

<p>If you compare the soft shadow only in image b) and d), you can notice two difference.</p>

<ol>
<li><p><strong>Jaggy difference</strong>. To the best of my knowledge, the jaggy shadow in UE4 is due to the cascading shadow map resolution. It seems that UE4 has a special correct for shadow if they are close to each other, as shown between the sphere and the box. Yet, I still need to figure out what that is.</p></li>

<li><p><strong>Shadow Softness</strong>. The path tracing soft shadow by default has PCSS features. The shadow is sharper closer to the object and more blurry further to it.</p></li>
</ol>

<p>So, this is all that we need to implement to apply ATAA to UE4 if we have tons of ray. However, there are still several difference we need to address before we can use ATAA in this simple situation. You can find more differences by comparing iamge b) and d). Yet I stopped here for the path tracing part.</p>

<p>Even with this, we can find a subset of features to apply ATAA, which will be detailed in applying ATAA to volume object rendering. In the next section, I will focus on how ATAA can be added to the post process pipeline in UE4 version 4.20.2 that I am using.</p>

<h2 id="postprocess-modification">Postprocess modification</h2>

<p>For basic postprocess pass editing, you can read Dr. Marc Olano’s course website for <a href="https://www.csee.umbc.edu/~olano/class/491-18-8/"><em>graphics for game</em></a> taught at UMBC. It introduces all information you need to know about UE4 to implement techniques like ATAA into UE4 rendering pipeline.</p>

<p>1). <strong>Segmentation</strong>. I duplicated the <code>FRCPassPostProcessTemporalAA</code> class as <code>~Plus</code>, and added an additional <code>FRenderingCompositeOutput</code> named <code>Segmentation</code>. In the pixel shader, the <code>TemporalAASample</code> function is called as usual. In addition, we need to record other information including:</p>

<ul>
<li><strong><code>Offscreen</code></strong> to indicate if there is no history. This pixel will use FXAA to denoise.</li>
<li><strong><code>Velocity</code></strong> to de-noise fast moving pixels with FXAA.</li>
<li><strong><code>ClassificationHistory</code></strong> from the last history render target, where the <code>z</code> component is the updated EMV value.</li>
<li><strong><code>DepthMagSobol</code></strong> to indicate the depth neighbor variance of the pixel.</li>
</ul>

<p>Those values will be collaboratively used to determine the segmentation texture.
You can see the <em>Segmentation</em> texture by enabling ATAA as <code>r.ATAA 1</code>, typing <code>r.ATAA.VisType 3</code> and <code>r.ATAA.Threshold 0</code> to see the <em>Segmentation</em> output.</p>

<p>2). <strong>Sparse path tracing</strong>. I duplicated the <code>FRCPassPostProcessDownsample</code> class as <code>FRCPassPostProcessSparsePathTracing</code> and registered it to the PostProcess graph after Bokeh pass, because it has compute shader templates, which is quite helpful for the implementation of the sparse path tracing. Then the path tracer mentioned above is implemented and traces pixels that only has high TAL. This post <a href="https://medium.com/@jcowles/gpu-ray-tracing-in-one-weekend-3e7d874b3b0f">GPU Ray Tracing in One Weekend</a> helps a lot for the implementation. However, there are three problems that I have run into:</p>

<ul>
<li><p>I did not previously know that <strong><em>all view uniform variables are not accessible in Compute Shader by default</em></strong> even after setting the view uniform for the global shader. We need to add codes to support them. I spent a lot of time to find it out.</p></li>

<li><p>Since we need to generate the camera ray, we need to remove the TAA dithering when obtaining the inverse view matrix. In UE4, all related matrix is managed in <code>ViewMatrices</code>. You can either get it there or set the dithering entries to zero.</p></li>

<li><p>There is no explicit API to upload <code>FRWBufferStructured</code> arrays, which I used to upload the geometry and LUTs. But you can write your own encapsulation. This question <a href="https://answers.unrealengine.com/questions/143750/create-structured-buffer-questions.html">Create structured buffer questions</a> asked at UE4 forum is very helpful. To get the basic geometry shape, I added one public API to the <code>FPrimitiveSceneInfo</code> class to access the primitive component, which is originally designed for debugging. Because this is the only way I find to get material properties dynamically like <code>Albedo</code>.</p></li>
</ul>

<p>To see the sparse tracing result, you can set <code>r.ATAA.1</code> and <code>r.ATAA.Combine 0</code>.If you want to see full tracing result, set <code>r.ATAA.Threshold 0</code>. But be prepared to see performance drop.</p>

<p>3). <strong>Combine</strong>. Now that we have the sparsely traced pixel colors, we can combine it with the original TAA pixels. To achieve this, I add an <code>ATAACombine</code> pass to combine TAA and Sparse path tracing result just before <code>Tonemaping</code>. The reason to do it before this pass is that all color operation is in linear RGB space and passes after this point will be converted to sRGB space that considers human vision characteristics.</p>

<p>What I did in this pass is to directly replace the original pixel marked as ATAA with the corresponding tracing color. You can type <code>r.ATAA.Combine 0</code> or <code>r.ATAA.Combine 1</code> to enable or disable the combination.</p>

<p>4). <strong>FXAA</strong>. The last modification is to modify the FXAA pass, where we can directly apply FXAA to pixels where the pixel is marked as FXAA in the segmentation image. Because we have already combined ATAA and TAA image, and those pixels from TAA  samples directly from the texture passed into TAA pass. You can set <code>r.ATAA.FXAA 1</code> to turn it on and <code>r.ATAA.FXAA 0</code> to turn it off.</p>

<h2 id="future-work">Future Work</h2>

<p><strong>Support volume objects</strong>. In this post, the supported material is only lambertian. To add volume objects that have the same behavior of UE4 can not be directly achieved by path tracing a volume. Because that will not have the same rendering result. Moreover, custom volume objects in UE4 does not have shadow, we need to ignore the volume objects that is hit after hitting an opaque surface in the tracer. At last, we need to correctly combine the volume objects that are transparent (I have added volume objects support in the next post).</p>

<p><strong>Correct global illuminance</strong>. If you observe the rendering result closely, the color has some mismatch, especially the shadow region that only relies on global illuminance. I used the sky irradiance modeled by Order 3 Spherical Harmonics in UE4 for this purpose. It is more complex than I thought.</p>

<p><strong>Divergence</strong>. Up till now,  the sparse tracing is not well optimized. For each (8,8,1) thread group. The ATAA flag is test for each pixel.
If only one pixel has high TAL, the other 63 threads are wasted waiting. Although the performance now is not bad,
I can achieve an amortized rays of 7.1G Rays/s on GTX 1080 (327M Rays/s for full screen tracing), it can be improved further by
aggregating ATAA pixels. I am still working on this.</p>

<p><strong>Ray object intersection optimization</strong>. In the current implementation, each ray iterates all objects in the scene to find a hit. With more objects and detailed meshes,
a acceleration structure (e.g., bounding volume hierarchy) is required to make it faster. Otherwise, we cannot use ATAA on all objects, we can only limit the application range
to few material type, like volume objects only.</p>

<h2 id="helpful-tips-on-mac">Helpful tips on Mac</h2>

<p>Since I am working on macOS, I do not have the access to the great tool <a href="https://renderdoc.org">RenderDoc</a>. If only it is already supported on Mac. So I goes for two basic tools to use (Hopefully there are better tools existing):</p>

<ol>
<li><em>Digital color meter</em> on mac for debugging color output in sRGB space.</li>
<li>Create unit test case to test the alignment of structures on CPU and GPU for <code>RWBufferStructured</code> in shader. Otherwise, I was unable to align them.</li>
</ol>


        

        

        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="https://ThisIsTian.github.io/post/adaptive-temporal-antialiasing-with-rtx-off/" data-toggle="tooltip" data-placement="top" title="Adaptive Temporal Antialiasing With RTX OFF">&larr; Previous Post</a>
            </li>
          
          
            <li class="next">
              <a href="https://ThisIsTian.github.io/post/add-volumetric-material-support/" data-toggle="tooltip" data-placement="top" title="Post 2: Add Volumetric Material Support">Next Post &rarr;</a>
            </li>
          
        </ul>
      


      
        
          
          <div class="disqus-comments">
            <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "xtiantian-gitlab-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
          </div>
          
        
        
      

    </div>
  </div>
</div>

    <footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
                <a href="mailto:xtiant1@gmail.com" title="Email me">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://twitter.com/ThisIsTian" title="Twitter">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://linkedin.com/in/tiantianxie" title="LinkedIn">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          <li>
            
            <a href="https://ThisIsTian.github.io/index.xml" title="RSS">
            
              <span class="fa-stack fa-lg">
                <i class="fas fa-circle fa-stack-2x"></i>
                <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          
            
              Tiantian Xie
            
          

          &nbsp;&bull;&nbsp;&copy;
          
            2019
          

          
            &nbsp;&bull;&nbsp;
            <a href="https://ThisIsTian.github.io">Titan de Tian</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="http://gohugo.io">Hugo v0.36.1</a> powered &nbsp;&bull;&nbsp; Theme by <a href="http://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a> adapted to <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a>
          
        </p>
      </div>
    </div>
  </div>
</footer>

<script  src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script  src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"></script>
<script>
    renderMathInElement(
        document.body,
        {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "\\[", right: "\\]", display: true},
                {left: "$", right: "$", display: false},
                {left: "\\(", right: "\\)", display: false}
            ]
        }
    );
</script>
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="https://ThisIsTian.github.io/js/main.js"></script>
<script src="https://ThisIsTian.github.io/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script> renderMathInElement(document.body); </script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script>
<script src="https://ThisIsTian.github.io/js/load-photoswipe.js"></script>








  </body>
</html>

